---
title: 了解kafka
date: 2021-05-11
tags:
- kafka
---
#了解kafka

[TOC]

## 0x01 前言

最近因为工作的需要使用了kafka，以前学大数据的时候听过，对这个消息队列一直很感兴趣，不过对kafka的功能还是一知半解，在此结合最近的应用和网上的资料进行总结，

## 0x02 kafka用来干什么

kafka是一种基于订阅-发布模式的消息系统/消息队列，具有分布式，备份和持久性日志服务的特点

直接生硬解释的话，很容易说不清，套用掘金大佬的博客举个例子

环境里有动物（生产者）和植物（消费者），动物生产co2，植物吸收co2，正常情况两个的速度一样，环境里的一切指标都很正常，生态平衡。

可是如果有一天植物突然都挂了，动物生产的co2无法得到消费，co2浓度越来越高，那么环境的生态就出了问题（系统宕机）。或者动物太多植物太少，co2生产速度过快，植物吃撑了需要休息一会来不及消费（消息堵塞，系统超时），温室效应就是这么来的( ╯□╰ )

如何解决这种问题呢，比较好的方法是在生态环境里准备一个机器，动物生产的co2被机器吸收，再按照一定的速度向植物排放co2，如果两边生产消费co2的速度有差异，还可以把co2暂时贮存在机器内部，帮助生态平衡，这个机器放到业务系统中就是kafka。co2其实就是「数据流」，系统之间的交互都是通过「数据流」来传输的，也叫「消息」

消息队列满了相当于“机器”存储的co2满了，环境里「二氧化碳」浓度太大，多放准备几个机器吸收co2保证生态平衡，就是 Kafka 的扩容。

## 0x03 kafka在业务上的功能

### 异步

kafka在业务逻辑上做到了“并行转串行，同步转异步”,能节省返回给用户响应的时间

拿用户注册的这个场景举例子

串行方式：将注册信息写入[数据库](http://lib.csdn.net/base/mysql)成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端

每一个步骤都需要得到前一级的相应，堵塞执行，总共耗时150ms

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445749271.png)

并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间

注册邮件和注册短信之间不需要互相等待，不过都需要等待信息写入数据库的相应，总共耗时100ms

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445751271.png)



按照以上约定，用户的响应时间其实只取决于注册信息写入数据库这一步。注册邮件，发送短信这种消息可以直接写入消息队列后返回，不用在等待这两个事件的返回，让他们去异步读取，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445753155.png)

### 模块解耦

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445756328.png)

继续套用原博客的图orz（原谅我不会作图），那电商的下单来说，传统的业务模式是在订单系统的代码中内嵌一行调用库存接口的代码

这样的话，如果在库存系统的代码执行时出现错误，会导致订单也失败，模块耦合度太大

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445758493.png)

套用消息队列后，订单系统可以直接把这个消息丢到队列中就不管了，快速返回给用户下单结果

库存系统得到这个消费并消费，实现模块之间的解耦合

### 分担流量

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445764218.jpg)

在高流量情况下，比如秒杀活动，大规模的用户请求打到某个模块应用上，如果加上处理请求的业务逻辑在返回，高并发很容易导致应用达到性能瓶颈挂掉。

可以设置一个接受用户请求的模块把用户请求发到消息队列后快速返回去处理别的请求，再让处理业务的模块去处理请求消息，来起到流量削峰的目的

### 日志处理

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445760718.png)

日志文件一般都是大量的，一次性传输的话容易造成系统堵塞，kafka可以作为一个中间件存储，日志采集的应用定时往队列写入日志消息，日志处理应用拉取消息处理分析，良好的实时性处理节省时间成本

比如说，用户在客户端的操作日志实时被kafka传输和处理，推荐系统得到结果再进行实时推送，用户在线上实时就能得到推荐的结果

### 消息通讯

![](https://cdn.jsdelivr.net/gh/iznilul/img/1645445762739.png)

kafka具备实时性消息传输，客户端可以通过订阅同一个消息队列的同一主题可以达到聊天室的效果

## 0x04 kafka的结构

结合上面kafka的co2例子介绍，我们可以简单的理解组成kafka的各个角色

生产者producer：动物

消费者consumer：植物

主题topic：这个可以理解为动物生产出的co2是有种类的，植物只能消费属于自己的那种co2，这样植物就可以有选择性的消费生产出的co2，确保生产者和消费者的对应关系

broker：机器，机器可以根据环境的要求布置多个

还有一个比较重要的角色zookeeper：

Producer 端使用 zookeeper 用来发现 broker 列表，以及和 Topic 下每个 partition leader 建立 socket 连接并发送消息。

Broker 端使用 zookeeper 用来注册 broker 信息，已经监测 partition leader 存活性。

 Consumer 端使用 zookeeper 用来注册 consumer 信息,其中包括 consumer 消费的 partition 列表等，同时也用来发现 broker 列表，并和 partition leader 建立 socket 连接，并获取消息。

![](https://user-gold-cdn.xitu.io/2019/2/23/1691a9721608d2e8?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

kafka的总体数据流动，producer往broker里指定的topic主题进行消息的生产，consumer往broker下指定的topic进行消息的消费，同一broker下topic分区（topic0有两个分区，topic1有一个分区），不同broker下进行topic的副本备份

## 0x05 参考资料

https://juejin.cn/post/6844903781902057480

https://www.cnblogs.com/zealoter/articles/12862144.html

